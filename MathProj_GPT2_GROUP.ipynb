{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd23779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages, in case Requirements.txt fails\n",
    "# !pip install spacy transformers numpy pandas datasets scikit-learn matplotlib evaluate wandb torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f10b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/bzb520k9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4c39808ad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import spacy\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\") \n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4456c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and Normalization Pipeline\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_shakespeare(text: str) -> str:\n",
    "\n",
    "    # remove any ALL CAPS words (Titles, character names, stage directions, etc.)\n",
    "    text = re.sub(r'\\b[A-Z]{2,}\\.', '', text)\n",
    "    text = re.sub(r'\\b[A-Z]{2,}\\b', '', text)\n",
    "\n",
    "    # lowercase normalization\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove ACT/SCENE markers\n",
    "    text = re.sub(r'\\bact\\s+[ivx]+\\b', '', text)\n",
    "    text = re.sub(r'\\bscene\\s+[ivx]+\\b', '', text)\n",
    "\n",
    "    # remove bracketed text [ ... ]\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # remove standalone numbers (often sonnet numbers or line counts)\n",
    "    text = re.sub(r'^\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # remove play headers and all-uppercase lines (likely metadata, not verse)\n",
    "    text = re.sub(r'^[A-Z\\s]{3,}$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # collapse multiple newlines\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # remove '\\n' as our model will not need to generate new lines in the style of Sonnets\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # strip leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Clean the file\n",
    "TXT_PATH = \"./model_0_shakespeare/shakespeare.txt\"\n",
    "CLEANED_TXT_PATH = \"./model_0_shakespeare/shakespeare_cleaned.txt\"\n",
    "\n",
    "with open(TXT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "cleaned_text = clean_shakespeare(raw_text)\n",
    "\n",
    "with open(CLEANED_TXT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f74656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 70932\n"
     ]
    }
   ],
   "source": [
    "# Load Text\n",
    "with open(CLEANED_TXT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "# Sentence segmentation (extract sentences from .txt)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = len(corpus) + 1000  # handle long corpus\n",
    "\n",
    "doc = nlp(corpus)\n",
    "sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "print(f\"Number of sentences: {len(sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b8ace95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example Sentences ===\n",
      "1: the complete works of william shakespeare by william shakespeare contents   ‚Äôs        ,    ‚Äôs ‚Äôs  a  ‚Äôs     ,     ,     ; ,     ‚Äôs  a ‚Äôs  from fairest creatures we desire increase, that thereby beauty‚Äôs rose might never die, but as the riper should by time decease, his tender heir might bear his memory: but thou contracted to thine own bright eyes, feed‚Äôst thy light‚Äôs flame with self-substantial fuel, making a famine where abundance lies, thyself thy foe, to thy sweet self too cruel: thou that art now the world‚Äôs fresh ornament, and only herald to the gaudy spring, within thine own bud buriest thy content, and, tender churl, mak‚Äôst waste in niggarding:     pity the world, or else this glutton be,     to eat the world‚Äôs due, by the grave and thee.\n",
      "2: when forty winters shall besiege thy brow, and dig deep trenches in thy beauty‚Äôs field, thy youth‚Äôs proud livery so gazed on now, will be a tattered weed of small worth held: then being asked, where all thy beauty lies, where all the treasure of thy lusty days; to say, within thine own deep sunken eyes, were an all-eating shame, and thriftless praise.\n",
      "3: how much more praise deserv‚Äôd thy beauty‚Äôs use, if thou couldst answer ‚Äòthis fair child of mine shall sum my count, and make my old excuse,‚Äô proving his beauty by succession thine.\n",
      "4: this were to be new made when thou art old,     and see thy blood warm when thou feel‚Äôst it cold.\n",
      "5: look in thy glass and tell the face thou viewest, now is the time that face should form another, whose fresh repair if now thou not renewest, thou dost beguile the world, unbless some mother.\n",
      "6: for where is she so fair whose uneared womb disdains the tillage of thy husbandry? or who is he so fond will be the tomb of his self-love to stop posterity?\n",
      "7: thou art thy mother‚Äôs glass\n",
      "8: and she in thee calls back the lovely april of her prime, so thou through windows of thine age shalt see, despite of wrinkles this thy golden time.\n",
      "9: but if thou live remembered not to be,     die single and thine image dies with thee.\n",
      "10: unthrifty loveliness why dost thou spend, upon thyself thy beauty‚Äôs legacy?\n",
      "\n",
      "Total sentences: 70932\n"
     ]
    }
   ],
   "source": [
    "# Explore sentences\n",
    "\n",
    "print(\"=== Example Sentences ===\")\n",
    "for i, s in enumerate(sentences[:10]):  # show first 10\n",
    "    print(f\"{i+1}: {s}\")\n",
    "print(\"\\nTotal sentences:\", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928425e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example Dataset Entries ===\n",
      "1: {'text': 'the complete works of william shakespeare by william shakespeare contents   ‚Äôs        ,    ‚Äôs ‚Äôs  a  ‚Äôs     ,     ,     ; ,     ‚Äôs  a ‚Äôs  from fairest creatures we desire increase, that thereby beauty‚Äôs rose might never die, but as the riper should by time decease, his tender heir might bear his memory: but thou contracted to thine own bright eyes, feed‚Äôst thy light‚Äôs flame with self-substantial fuel, making a famine where abundance lies, thyself thy foe, to thy sweet self too cruel: thou that art now the world‚Äôs fresh ornament, and only herald to the gaudy spring, within thine own bud buriest thy content, and, tender churl, mak‚Äôst waste in niggarding:     pity the world, or else this glutton be,     to eat the world‚Äôs due, by the grave and thee.'}\n",
      "2: {'text': 'when forty winters shall besiege thy brow, and dig deep trenches in thy beauty‚Äôs field, thy youth‚Äôs proud livery so gazed on now, will be a tattered weed of small worth held: then being asked, where all thy beauty lies, where all the treasure of thy lusty days; to say, within thine own deep sunken eyes, were an all-eating shame, and thriftless praise.'}\n",
      "3: {'text': 'how much more praise deserv‚Äôd thy beauty‚Äôs use, if thou couldst answer ‚Äòthis fair child of mine shall sum my count, and make my old excuse,‚Äô proving his beauty by succession thine.'}\n",
      "4: {'text': 'this were to be new made when thou art old,     and see thy blood warm when thou feel‚Äôst it cold.'}\n",
      "5: {'text': 'look in thy glass and tell the face thou viewest, now is the time that face should form another, whose fresh repair if now thou not renewest, thou dost beguile the world, unbless some mother.'}\n",
      "6: {'text': 'for where is she so fair whose uneared womb disdains the tillage of thy husbandry? or who is he so fond will be the tomb of his self-love to stop posterity?'}\n",
      "7: {'text': 'thou art thy mother‚Äôs glass'}\n",
      "8: {'text': 'and she in thee calls back the lovely april of her prime, so thou through windows of thine age shalt see, despite of wrinkles this thy golden time.'}\n",
      "9: {'text': 'but if thou live remembered not to be,     die single and thine image dies with thee.'}\n",
      "10: {'text': 'unthrifty loveliness why dost thou spend, upon thyself thy beauty‚Äôs legacy?'}\n",
      "\n",
      "Dataset length: 70932\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": sentences})\n",
    "\n",
    "# Explore Dataset\n",
    "\n",
    "print(\"\\n=== Example Dataset Entries ===\")\n",
    "for i in range(10):  # show first 10\n",
    "    print(f\"{i+1}: {dataset[i]}\")\n",
    "print(\"\\nDataset length:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3bd2cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831838e6093d49c98995f6d48fd7bb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70932 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load pre-trained model\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# GPT-2 doesn‚Äôt have a padding token by default\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "        #return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "241d150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to use on WSL for training with GPU\n",
    "\n",
    "#tokenized_dataset.save_to_disk(\"shakespeare_tokenized\")\n",
    "\n",
    "\n",
    "#Open on WSL \n",
    "\n",
    "#tokenized_dataset = load_from_disk(\"shakespeare_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effae1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/eval\n",
    "split = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split[\"train\"]\n",
    "eval_dataset = split[\"test\"]\n",
    "\n",
    "# Metric: Perplexity (based on loss)\n",
    "# Hugging Face's `evaluate` doesn't include perplexity directly,\n",
    "# but we can derive it from cross-entropy loss.\n",
    "def compute_metrics(eval_pred):\n",
    "    loss = eval_pred.metrics[\"eval_loss\"] if \"eval_loss\" in eval_pred.metrics else None\n",
    "    if loss is None:\n",
    "        return {}\n",
    "    perplexity = np.exp(loss)\n",
    "    return {\"perplexity\": perplexity, \"loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a54f3e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations for Training NO IDEA IF IT WORKS\n",
    "\n",
    "import transformers\n",
    "from transformers import TrainerCallback\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "eval_steps = []\n",
    "\n",
    "def plot_metrics():\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(eval_steps, eval_losses, label=\"Eval Loss\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "class PlotCallback(transformers.TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if \"loss\" in logs:\n",
    "                train_losses.append(logs[\"loss\"])\n",
    "            if \"eval_loss\" in logs:\n",
    "                eval_losses.append(logs[\"eval_loss\"])\n",
    "                eval_steps.append(state.global_step)\n",
    "                plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95576100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: /home/alvisngan/Documents/george_brown/math_dl/AASD4011_term_project/.venv/bin/python\n",
      "torch: 2.7.1+cu126 /home/alvisngan/Documents/george_brown/math_dl/AASD4011_term_project/.venv/lib/python3.13/site-packages/torch/__init__.py\n",
      "transformers: 4.56.2 /home/alvisngan/Documents/george_brown/math_dl/AASD4011_term_project/.venv/lib/python3.13/site-packages/transformers/__init__.py\n",
      "accelerate: 1.1.0 /home/alvisngan/Documents/george_brown/math_dl/AASD4011_term_project/.venv/lib/python3.13/site-packages/accelerate/__init__.py\n",
      "tensorboard: 2.20.0 /home/alvisngan/Documents/george_brown/math_dl/AASD4011_term_project/.venv/lib/python3.13/site-packages/tensorboard/__init__.py\n",
      "Trainer OK.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nWorks for me - Alvis\\npython          3.13.7\\ntorch           2.7.1+cu126\\ntransformers    4.56.2\\naccelerate      1.1.0\\ntensorboard     2.20.0\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show versions + import paths (DEBUG)\n",
    "import sys\n",
    "import torch, transformers, accelerate, tensorboard\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__, getattr(torch, \"__file__\", None))\n",
    "print(\"transformers:\", transformers.__version__, getattr(transformers, \"__file__\", None))\n",
    "print(\"accelerate:\", accelerate.__version__, getattr(accelerate, \"__file__\", None))\n",
    "print(\"tensorboard:\", tensorboard.__version__, getattr(tensorboard, \"__file__\", None))\n",
    "\n",
    "# 3) Minimal Trainer dry run to ensure import path is sane\n",
    "from transformers import TrainingArguments, Trainer\n",
    "print(\"Trainer OK.\")\n",
    "\n",
    "\"\"\" \n",
    "Works for me - Alvis\n",
    "python          3.13.7\n",
    "torch           2.7.1+cu126\n",
    "transformers    4.56.2\n",
    "accelerate      1.1.0\n",
    "tensorboard     2.20.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1607d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate, inspect\n",
    "\n",
    "# FIX TRANSFORMER (IDK LOL IT'S STUPID)\n",
    "\n",
    "# Only patch if needed, and only once\n",
    "_unwrap = accelerate.Accelerator.unwrap_model\n",
    "sig = str(inspect.signature(_unwrap))\n",
    "\n",
    "if \"keep_torch_compile\" not in sig and not getattr(_unwrap, \"_patched_keep_torch_compile\", False):\n",
    "    _orig_unwrap = _unwrap\n",
    "    def _unwrap_compat(self, model, *args, **kwargs):\n",
    "        # drop unknown kwarg if present\n",
    "        kwargs.pop(\"keep_torch_compile\", None)\n",
    "        return _orig_unwrap(self, model, *args, **kwargs)\n",
    "    _unwrap_compat._patched_keep_torch_compile = True\n",
    "    accelerate.Accelerator.unwrap_model = _unwrap_compat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc9e110",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m     base_args[\u001b[33m\"\u001b[39m\u001b[33meval_strategy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33msteps\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# else: leave eval off if neither exists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbase_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m#Initialize Trainer\u001b[39;00m\n\u001b[32m     99\u001b[39m trainer = Trainer(\n\u001b[32m    100\u001b[39m     model=model,\n\u001b[32m    101\u001b[39m     args=args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# callbacks=[PlotCallback()],   # üëà add live plotting\u001b[39;00m\n\u001b[32m    106\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"C:/Users/Gaels/MATH-Proj-GPT2/shakespeare_gpt2\",\n",
    "#     #eval_strategy=\"epoch\",\n",
    "#     learning_rate=5e-5,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     disable_tqdm=False,\n",
    "#     logging_dir=\"C:/Users/Gaels/MATH-Proj-GPT2/shakespeare_logs\",\n",
    "#     logging_steps=50,\n",
    "#     logging_strategy=\"steps\",\n",
    "#     eval_steps=200,\n",
    "#     logging_first_step=True,\n",
    "# )\n",
    "\n",
    "# args = TrainingArguments(\n",
    "#     output_dir=\"./shakespeare_gpt2\",\n",
    "#     logging_dir=\"./shakespeare_logs\",\n",
    "#     per_device_train_batch_size=1,\n",
    "#     per_device_eval_batch_size=1,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     learning_rate=5e-5,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     eval_strategy=\"steps\",      # ‚Üê use this\n",
    "#     eval_steps=200,\n",
    "#     logging_strategy=\"steps\",\n",
    "#     logging_steps=50,\n",
    "#     report_to=[\"tensorboard\"],\n",
    "#     fp16=True,                  # OK on your GPU\n",
    "# )\n",
    "\n",
    "# --- Memory helpers (do this before Trainer) ---\n",
    "model.config.use_cache = False\n",
    "if hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "# --- Build args in a version-safe way ---\n",
    "# base_args = dict(\n",
    "#     output_dir=\"./shakespeare_gpt2\",\n",
    "#     logging_dir=\"./shakespeare_logs\",\n",
    "#     per_device_train_batch_size=4,\n",
    "#     per_device_eval_batch_size=4,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     learning_rate=5e-5,\n",
    "#     num_train_epochs=3,\n",
    "#     weight_decay=0.01,\n",
    "#     fp16=True,                      # works on 1070 Ti\n",
    "#     report_to=[\"tensorboard\"],\n",
    "#     logging_strategy=\"steps\",\n",
    "#     logging_steps=50,\n",
    "#     save_strategy=\"epoch\",          # keep epoch saves (lighter on VRAM spikes)\n",
    "#     eval_steps=200,\n",
    "#     eval_accumulation_steps=1,\n",
    "#     dataloader_pin_memory=False,       # ‚Üê important\n",
    "#     dataloader_num_workers=0,          # ‚Üê important\n",
    "# )\n",
    "\n",
    "# --- Build args WITHOUT any eval/evaluation key here ---\n",
    "base_args = dict(\n",
    "    output_dir=\"./shakespeare_gpt2\",\n",
    "    logging_dir=\"./shakespeare_logs\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=200,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=1,\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_num_workers=0,\n",
    "    gradient_checkpointing=True,\n",
    "    load_best_model_at_end=False,\n",
    ")\n",
    "\n",
    "# Pick ONE correct key based on your transformers version\n",
    "target_eval = \"no\"  # use \"steps\"/\"epoch\" if you want evaluation\n",
    "params = inspect.signature(TrainingArguments).parameters\n",
    "if \"evaluation_strategy\" in params:          # HF v4.x\n",
    "    base_args[\"evaluation_strategy\"] = target_eval\n",
    "elif \"eval_strategy\" in params:              # HF v5.x\n",
    "    base_args[\"eval_strategy\"] = target_eval\n",
    "\n",
    "args = TrainingArguments(**base_args)\n",
    "\n",
    "# params = inspect.signature(TrainingArguments).parameters\n",
    "# if \"evaluation_strategy\" in params:          # HF v4.x\n",
    "#     base_args[\"evaluation_strategy\"] = \"steps\"\n",
    "# elif \"eval_strategy\" in params:              # HF v5.x\n",
    "#     base_args[\"eval_strategy\"] = \"steps\"\n",
    "# # else: leave eval off if neither exists\n",
    "\n",
    "# args = TrainingArguments(**base_args)\n",
    "\n",
    "\n",
    "#Initialize Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[PlotCallback()],   # üëà add live plotting\n",
    ")\n",
    "\n",
    "#Train the model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model + Tokenizer\n",
    "\n",
    "save_dir = \"shakespeare_gpt2_final\"\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28521f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "\n",
    "# 1. Perplexity Evaluation\n",
    "print(\"\\n--- Perplexity Evaluation ---\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Loss: {eval_results['eval_loss']}\")\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss'])}\")\n",
    "\n",
    "# 3. BLEU/ROUGE Scores\n",
    "print(\"\\n--- BLEU/ROUGE Evaluation ---\")\n",
    "import evaluate\n",
    "metric = evaluate.load(\"rouge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference (text generation)\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=save_dir,\n",
    "    tokenizer=save_dir,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"\\n=== Sample Shakespearean Text ===\\n\")\n",
    "print(generator(\"to be, or not to be\", max_length=100, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
