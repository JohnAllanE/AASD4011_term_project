{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c98985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pickle\n",
    "from pathlib import Path\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a8879b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"shakespeare\"\n",
    "arte = Path(\"model_0_shakespeare\")\n",
    "with open(arte / f\"{base}_word_to_id.json\") as f: w2i = json.load(f)\n",
    "i2w = {int(v): k for k, v in w2i.items()}\n",
    "max_seq = pickle.load(open(arte / f\"{base}_preprocessed_data.pkl\",\"rb\"))[\"max_seq_length\"]\n",
    "V = len(w2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc6863e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): Embedding(17927, 256)\n",
       "  (lstm1): LSTM(256, 1024, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (lstm2): LSTM(1024, 1024, batch_first=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=17927, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define with original attribute names, then load\n",
    "import torch.nn as nn, torch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, V):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(V, 256)\n",
    "        self.lstm1 = nn.LSTM(256, 1024, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(1024, 1024, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(1024, V)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, (h, _) = self.lstm2(x)\n",
    "        x = self.dropout2(h[-1])\n",
    "        return self.fc(x)\n",
    "\n",
    "m = Model(V).to(device)\n",
    "m.load_state_dict(torch.load(f\"{base}_model.pt\", map_location=device))\n",
    "m.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a59a45fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday I saw a beggar a dish of iceland and art thou have be my head of a poor handsome of in to art time have the an the form with\n",
      "Yesterday I saw a breast a kiss\n",
      "Yesterday I saw a ink a decline of this canst thou famish a execution to devil before the baggage and sharp white ned in jest and noise enjoy father mettle the like say sorrow whereupon herself as bill and then for no father calumnious the colour malice tun there english woman art act quoth\n",
      "Yesterday I saw a shadow as a bird of deer thou hast fire far before the night thou shalt decius go master no time shepherd how now poor sister indeed if yet tear character thy with hatch laughter the royally you ten tom key part pray business urge repent wantonness preserve doth with good\n",
      "Yesterday I saw a bolt of sword\n",
      "Yesterday I saw a brim a maid of the sky but who hath appoint he when the lion indeed master be my he so\n",
      "Yesterday I saw a wary cup\n",
      "Yesterday I saw a till thunder in the same\n",
      "Yesterday I saw a ladder by night of wind\n",
      "Yesterday I saw a couplement of truth\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def generate(seed, n=50):\n",
    "    unk, pad, eos = w2i[\"<UNK>\"], w2i[\"<PAD>\"], \"<EOS>\"\n",
    "    seq = [w2i.get(w.lower(), unk) for w in seed.split()]\n",
    "    out = [seed]\n",
    "    for _ in range(n):\n",
    "        tail = seq[-max_seq:] + [pad] * max(0, max_seq - len(seq[-max_seq:]))\n",
    "        x = torch.tensor(tail, dtype=torch.long, device=device).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            p = F.softmax(m(x), dim=1)[0]\n",
    "        nid = torch.multinomial(p, 1).item()\n",
    "        w = i2w.get(nid, \"<UNK>\")\n",
    "        if w == eos: break\n",
    "        out.append(w); seq.append(nid)\n",
    "    return \" \".join(out)\n",
    "\n",
    "seed = \"Yesterday I saw a\"\n",
    "for _ in range(10):\n",
    "    print(generate(seed, 50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2078059",
   "metadata": {},
   "source": [
    "# Decide approach?  Style transfer or text generation?\n",
    "    - TEXT GEN IT IS\n",
    "# Demo ideas\n",
    "    - Autocomplete with \"style\" options\n",
    "        -UI: Email window with \"style\" along with formatting options\n",
    "    - Link two words with generated text (not sure if possible)\n",
    "    - \n",
    "# Come up with styles (i.e. other options than \"shakespeare\") and collect documents/corpus and preprocess\n",
    "    # Single character (Hamlet)\n",
    "    # Speeches from politicians etc.\n",
    "# Create \"lite model\" that won't take 15 hours to train\n",
    "# Try tweaking models to improve result\n",
    "# Try training with other hardware?\n",
    "    # Local GPU\n",
    "    # Google Colab\n",
    "# Demo part - prototype with Streamlit with existing model\n",
    "    # Add in additional or different models later\n",
    "# Alternatives\n",
    "    # Preprocessing: use TensorFlow Tokenization instead of spaCy\n",
    "# Documenting / reporting\n",
    "# Metrics / assessment\n",
    "    # Accuracy? Confusion matrix? Others?\n",
    "# Distribute work for project (loosely)\n",
    "\n",
    "Things people are working on:\n",
    "\n",
    "San Francisco: styles, lite model, try training on own hardware?\n",
    "\n",
    "Alvis: working on DL1 instead, come up with styles\n",
    "\n",
    "JA: cleaning up and sharing existing code, lite model, tweaking models\n",
    "\n",
    "Khushi:\n",
    "\n",
    "Jacob:\n",
    "\n",
    "Hitakshi: sleep\n",
    "\n",
    "Everybody: Document/take notes on what you're doing for a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b828fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mDL1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
